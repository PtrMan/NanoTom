{
 "cells": [
  {
   "cell_type": "raw",
   "id": "45ed570e-cb7e-41f5-a0fe-501484a6120f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "implementation of BACKEND of Q&A system!!!\n",
    "\n",
    "* search in text-database for keywords in python\n",
    "* use LM for final stage of question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1575ad5f-f3e4-4f67-a6e5-5d14a1216127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6abdaa1137744af784832c1ae4fc15e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/166 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ff50f4c9ec4640a51b23ae4e17d50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b419d86592e46e2860093e204511ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generalized model loading\n",
    "\n",
    "import torch\n",
    "from GenericMlUtils import *\n",
    "\n",
    "print('load model...')\n",
    "\n",
    "if False:\n",
    "    pass\n",
    "elif False:\n",
    "    modelName = \"bigscience/bloomz-7b1\" # recommended for instruction prompting in non-english\n",
    "    \n",
    "    # code from https://huggingface.co/bigscience/bloomz-7b1-p3\n",
    "    from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "    \n",
    "    m = ModelBundle()\n",
    "    m.tokenizer = AutoTokenizer.from_pretrained(modelName)\n",
    "    m.model = AutoModelForCausalLM.from_pretrained(modelName, torch_dtype=\"auto\", device_map=\"auto\")\n",
    "\n",
    "    #inputs = tokenizer.encode(\"Translate to English: Je tâ€™aime.\", return_tensors=\"pt\").to(\"cuda\")\n",
    "    #outputs = model.generate(inputs)\n",
    "    #print(tokenizer.decode(outputs[0]))\n",
    "    \n",
    "    pass\n",
    "elif True: # load galactica\n",
    "    from transformers import AutoTokenizer, OPTForCausalLM\n",
    "\n",
    "    modelName = \"facebook/galactica-30b\" # to big, explodes GPU\n",
    "    modelName = \"facebook/galactica-6.7b\"\n",
    "\n",
    "    # code is from https://github.com/paperswithcode/galai\n",
    "    m = ModelBundle()\n",
    "    m.model = OPTForCausalLM.from_pretrained(modelName, device_map=\"auto\")\n",
    "    #m.model = OPTForCausalLM.from_pretrained(modelName, device_map=\"auto\",   load_in_8bit=True)\n",
    "    \n",
    "    #model = OPTForCausalLM.from_pretrained(modelName, device_map=\"auto\", low_cpu_mem_usage=True, torch_dtype=torch.bfloat16)\n",
    "    m.tokenizer = AutoTokenizer.from_pretrained(modelName)\n",
    "\n",
    "\n",
    "elif True: # load opt\n",
    "    from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "    m = ModelBundle()\n",
    "    \n",
    "    #modelName = \"facebook/opt-30b\"\n",
    "    modelName = \"facebook/opt-13b\"\n",
    "    \n",
    "\n",
    "    # from https://huggingface.co/facebook/opt-30b\n",
    "\n",
    "    m.model = AutoModelForCausalLM.from_pretrained(modelName, torch_dtype=torch.float16)\n",
    "    m.model = m.model.cuda()\n",
    "\n",
    "    # the fast tokenizer currently does not work correctly\n",
    "\n",
    "    m.tokenizer = AutoTokenizer.from_pretrained(modelName, use_fast=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "421d475d-ea15-4107-9cab-7d27a6554171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper to open a file and search for a keyword in it, return all lines which match\n",
    "def z88844(path, searchStrings):\n",
    "    f = open(path, 'r')\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    \n",
    "    hitLines = []\n",
    "    \n",
    "    for iLine in lines:\n",
    "        if iLine[-1] == '\\n':\n",
    "            iLine = iLine[:-1]\n",
    "        \n",
    "        \n",
    "        # remove new style seperator between raw text and reformulated text\n",
    "        idx1 = iLine.find(' #%%^ ')\n",
    "        if idx1 != -1:\n",
    "            iLine = iLine[idx1+len(' #%%^ '):]\n",
    "        \n",
    "        iLine0 = iLine.lower() # convert to lower case for better search by keywords\n",
    "        \n",
    "        \n",
    "        hitKeywordCnt = 0\n",
    "        for iKeyword in searchStrings:\n",
    "            if iLine0.find(iKeyword+' ') != -1:\n",
    "                hitKeywordCnt = hitKeywordCnt+1\n",
    "        \n",
    "        if hitKeywordCnt == len(searchStrings):\n",
    "            print(iLine)\n",
    "            hitLines.append(iLine)\n",
    "    \n",
    "    return hitLines\n",
    "\n",
    "\n",
    "# searches and returns all lines which contain the mentioned keywords\n",
    "def z673783(keywords):\n",
    "    path = '.'\n",
    "    import os\n",
    "    filenames = os.listdir(path)\n",
    "\n",
    "    # we only care about filenames which are entries of our database\n",
    "    filenames = list(filter(lambda iv: iv.find('out_')!=-1, filenames))\n",
    "\n",
    "    #print(filenames) # DBG\n",
    "\n",
    "    allHitlines = [] # strings of the lines which match up\n",
    "\n",
    "    for iFilename in filenames:\n",
    "        allHitlines = allHitlines+z88844(iFilename, keywords)\n",
    "    \n",
    "    return allHitlines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c1502db-8dad-40dd-a248-597ab41f79ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agi', 'is a']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'z673783' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(allHitlines) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;66;03m# didnt find any answers yet?\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# search in database of facts for all lines which match the keywords as best as possible\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(keywords1))\n\u001b[0;32m---> 45\u001b[0m     allHitlines \u001b[38;5;241m=\u001b[39m \u001b[43mz673783\u001b[49m(keywords1)\n\u001b[1;32m     47\u001b[0m keywords1 \u001b[38;5;241m=\u001b[39m keywords \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis an\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(allHitlines) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;66;03m# didnt find any answers yet?\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# search in database of facts for all lines which match the keywords as best as possible\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'z673783' is not defined"
     ]
    }
   ],
   "source": [
    "questionTxt0 = 'What is AGI?' # 15.12.2022    finds correct answer\n",
    "\n",
    "# extracts keywords of a question\n",
    "def extractKeywords(questionTxt):\n",
    "    questionTxt0 = questionTxt.lower()\n",
    "    questionTxt0 = questionTxt0.replace('?', ' ? ')\n",
    "    \n",
    "    # stemming\n",
    "    questionTxt0 = questionTxt0.replace('dealing', 'deals')\n",
    "    \n",
    "    tokens = questionTxt0.split(' ')\n",
    "    outKeywords = []\n",
    "    for iToken in tokens:\n",
    "        if iToken == '':\n",
    "            continue\n",
    "        \n",
    "        blacklist = ['is', 'what', 'with', '?', 'who', 'when', 'a']\n",
    "        if iToken in blacklist:\n",
    "            continue # ignore token as keyword\n",
    "        \n",
    "        outKeywords.append(iToken)\n",
    "    \n",
    "    return outKeywords\n",
    "\n",
    "keywords = extractKeywords(questionTxt0)\n",
    "\n",
    "\n",
    "allHitlines = []\n",
    "\n",
    "# HACK< we try definitions with 'is a' first, take the results if it returns any > \n",
    "keywords1 = keywords + ['is a']\n",
    "if len(allHitlines) == 0: # didnt find any answers yet?\n",
    "    # search in database of facts for all lines which match the keywords as best as possible\n",
    "    print(str(keywords1))\n",
    "    allHitlines = z673783(keywords1)\n",
    "\n",
    "keywords1 = keywords + ['is an']\n",
    "if len(allHitlines) == 0: # didnt find any answers yet?\n",
    "    # search in database of facts for all lines which match the keywords as best as possible\n",
    "    print(str(keywords1))\n",
    "    allHitlines = z673783(keywords1)\n",
    "\n",
    "\n",
    "# else we backup to search by taking keywords into account\n",
    "if len(allHitlines) == 0:\n",
    "    # search in database of facts for all lines which match the keywords as best as possible\n",
    "    allHitlines = z673783(keywords)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# process lines and get rid of knowledge system idocracies\n",
    "allHitlines2 = []\n",
    "for iLine in allHitlines:\n",
    "    if iLine.endswith('? YES'): # is of a statement form\n",
    "        allHitlines2.append(iLine[:-5]+'.') # add line without YES as statement\n",
    "\n",
    "\n",
    "\n",
    "# compose eligable lines \n",
    "eligableKnowledgeLines = '\\n'.join(allHitlines2)\n",
    "\n",
    "\n",
    "# purpose: answer side for Q&A system\n",
    "# model bigscience/bloom-7b1     result: gives the CORRECT answer!\n",
    "# model galactica-6.7b     result: gives the CORRECT answer!\n",
    "prompt = \"\"\"\"Statistics deals with the planning of data collection in terms of the design of surveys and experiments.\n",
    "\n",
    "Q: What is statistics dealing with?\n",
    "A:\"\"\"\n",
    "\n",
    "\n",
    "prompt = f\"\"\"{eligableKnowledgeLines}\n",
    "\n",
    "Q: {questionTxt0}\n",
    "A:\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "res0 = None\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.doSample = False\n",
    "config.topP = 0.31\n",
    "print('\\n\\n\\n\\n')\n",
    "print(prompt)\n",
    "if True: # run prompt?\n",
    "    print('~run')\n",
    "    res0 = inf(m, prompt, 300, config)[1:]\n",
    "    print('~done')\n",
    "    print('===')\n",
    "    print(res0)\n",
    "\n",
    "# process answer to extract relevant parts\n",
    "res1 = res0[1:]\n",
    "\n",
    "\n",
    "res2 = None \n",
    "idx0 = res1.find('\\nQ:')\n",
    "if idx0 != -1:\n",
    "    res2 = res1[:idx0]\n",
    "\n",
    "# 'res2' is the answer to the question\n",
    "print('ANSWER:')\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2eb95e-aaa4-47db-86b1-5d756f9180b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
